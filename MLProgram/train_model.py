import os
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import class_weight
import json

# ============================================================
# 0ï¸âƒ£ ë°ì´í„° ê²½ë¡œ ì§€ì • (ğŸ”¹ ì—¬ê¸°ë§Œ ë³€ê²½!)
# ============================================================
data_dir = "data_images"  # âœ… ìƒˆë¡œ ë§Œë“  ì´ë¯¸ì§€ í´ë” ê²½ë¡œ

# -----------------------------
# 1ï¸âƒ£ ë°ì´í„° íƒ€ì… ìë™ ê°ì§€
# -----------------------------
def detect_data_type(data_dir):
    for root, _, files in os.walk(data_dir):
        for f in files:
            if f.lower().endswith(('.jpg', '.jpeg', '.png')):
                return "image"
            if f.lower().endswith(('.npy', '.csv')):
                return "vector"
    return None

data_type = detect_data_type(data_dir)
if not data_type:
    raise ValueError(f"âŒ {data_dir} í´ë”ì— .jpg/.png ë˜ëŠ” .npy/.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")

print(f"ğŸ“‚ ë°ì´í„° íƒ€ì… ê°ì§€ë¨: {data_type}")

# -----------------------------
# 2ï¸âƒ£ ì´ë¯¸ì§€ ë°ì´í„° (CNN)
# -----------------------------
def train_image_model():
    print("ğŸ§  CNN ê¸°ë°˜ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì¤‘...")

    datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=15,
        width_shift_range=0.1,
        height_shift_range=0.1,
        zoom_range=0.1,
        horizontal_flip=True,
        validation_split=0.2
    )

    train_gen = datagen.flow_from_directory(
        data_dir,
        target_size=(128, 128),
        batch_size=32,
        class_mode='categorical',
        subset='training'
    )
    val_gen = datagen.flow_from_directory(
        data_dir,
        target_size=(128, 128),
        batch_size=32,
        class_mode='categorical',
        subset='validation'
    )

    os.makedirs("model", exist_ok=True)
    with open('model/class_indices.json', 'w', encoding='utf-8') as f:
        json.dump(train_gen.class_indices, f, ensure_ascii=False, indent=2)

    print("ğŸ§© í´ë˜ìŠ¤ ì¸ë±ìŠ¤ ë§¤í•‘:", train_gen.class_indices)

    model = models.Sequential([
        layers.Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),
        layers.MaxPooling2D(2,2),
        layers.Conv2D(64, (3,3), activation='relu'),
        layers.MaxPooling2D(2,2),
        layers.Conv2D(128, (3,3), activation='relu'),
        layers.MaxPooling2D(2,2),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.4),
        layers.Dense(train_gen.num_classes, activation='softmax')
    ])

    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    labels = train_gen.classes
    weights = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(labels),
    y=labels
    )
    class_weights = dict(enumerate(weights))
    print("âš–ï¸ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©:", class_weights)


    history = model.fit(
        train_gen,
        validation_data=val_gen,
        epochs=15,
        class_weight=class_weights
    )

    model.save('model/cube_classifier.keras')
    print("âœ… CNN ì´ë¯¸ì§€ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")

# -----------------------------
# 3ï¸âƒ£ ë²¡í„° ë°ì´í„° (MLP)
# -----------------------------
def train_vector_model():
    print("ğŸ§© MLP ê¸°ë°˜ í”¼ì²˜ ë²¡í„° ëª¨ë¸ í•™ìŠµ ì¤‘... (ìƒëµ ê°€ëŠ¥)")

# -----------------------------
# 4ï¸âƒ£ ìë™ ì‹¤í–‰
# -----------------------------
if data_type == "image":
    train_image_model()
elif data_type == "vector":
    train_vector_model()
else:
    raise ValueError("âŒ ë°ì´í„° íƒ€ì…ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

print("âœ… ì „ì²´ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
